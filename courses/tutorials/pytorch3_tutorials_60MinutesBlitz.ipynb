{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with Pytorch: A 60 Minutes Blitz "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://pytorch.org/tutorials/beginner/deep_learning_60min_blitz.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What's Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Getting started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors are similar to NumPy’s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a 5x3 matrix, uninitialized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.1.post2\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "1.00000e-42 *\n",
       "  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000\n",
       "  0.0000  0.0000  0.0000\n",
       "  0.0000  1.4798  0.0000\n",
       "  0.0000  0.5577  0.0000\n",
       "[torch.FloatTensor of size 5x3]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.Tensor(5,3); x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a randomly initialized matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.6226  0.8266  0.3955\n",
       " 0.7972  0.6164  0.9152\n",
       " 0.5178  0.6741  0.4506\n",
       " 0.5908  0.7700  0.3202\n",
       " 0.3578  0.5356  0.9206\n",
       "[torch.FloatTensor of size 5x3]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.rand(5,3); x # Returns a tensor filled with random numbers from a uniform distribution on the interval [0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:\n",
    "- torch.Size is in fact a tuple, so it supports all tuple operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1.2 Operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.2481  0.1875  0.2823\n",
       " 0.4857  0.3078  0.6057\n",
       " 0.3550  0.4367  0.2077\n",
       " 0.6171  0.1952  0.5085\n",
       " 0.6090  0.4724  0.1952\n",
       "[torch.FloatTensor of size 5x3]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.rand(5,3);y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.8706  1.0141  0.6779\n",
       " 1.2829  0.9242  1.5209\n",
       " 0.8728  1.1108  0.6584\n",
       " 1.2079  0.9652  0.8287\n",
       " 0.9668  1.0081  1.1158\n",
       "[torch.FloatTensor of size 5x3]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x+y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.8706  1.0141  0.6779\n",
       " 1.2829  0.9242  1.5209\n",
       " 0.8728  1.1108  0.6584\n",
       " 1.2079  0.9652  0.8287\n",
       " 0.9668  1.0081  1.1158\n",
       "[torch.FloatTensor of size 5x3]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.add(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.8706  1.0141  0.6779\n",
       " 1.2829  0.9242  1.5209\n",
       " 0.8728  1.1108  0.6584\n",
       " 1.2079  0.9652  0.8287\n",
       " 0.9668  1.0081  1.1158\n",
       "[torch.FloatTensor of size 5x3]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = torch.Tensor(5,3)\n",
    "torch.add(x,y,out=result)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.8706  1.0141  0.6779\n",
       " 1.2829  0.9242  1.5209\n",
       " 0.8728  1.1108  0.6584\n",
       " 1.2079  0.9652  0.8287\n",
       " 0.9668  1.0081  1.1158\n",
       "[torch.FloatTensor of size 5x3]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Any operation that mutates a tensor in-place is post-fixed with an _. For example: x.copy_(y), x.t_(), will change x.\n",
    "y.add_(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use standard NumPy-like indexing with all bells and whistles!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.8266\n",
       " 0.6164\n",
       " 0.6741\n",
       " 0.7700\n",
       " 0.5356\n",
       "[torch.FloatTensor of size 5]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[:,1].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Resizing: If you want to resize/reshape tensor, you can use torch.view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.9926 -0.9778 -0.1957  0.6659\n",
       " 0.3114 -0.3543 -1.1168 -0.2368\n",
       " 0.0806  1.4061 -0.4829  0.0666\n",
       "-2.0539  1.2236  0.1225  1.3195\n",
       "[torch.FloatTensor of size 4x4]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4,4); x # Returns a tensor filled with random numbers from a normal distribution with mean 0 and variance 1 (also called the standard normal distribution)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.9926\n",
       "-0.9778\n",
       "-0.1957\n",
       " 0.6659\n",
       " 0.3114\n",
       "-0.3543\n",
       "-1.1168\n",
       "-0.2368\n",
       " 0.0806\n",
       " 1.4061\n",
       "-0.4829\n",
       " 0.0666\n",
       "-2.0539\n",
       " 1.2236\n",
       " 0.1225\n",
       " 1.3195\n",
       "[torch.FloatTensor of size 16]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x.view(16); y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.9926 -0.9778 -0.1957  0.6659  0.3114 -0.3543 -1.1168 -0.2368\n",
       " 0.0806  1.4061 -0.4829  0.0666 -2.0539  1.2236  0.1225  1.3195\n",
       "[torch.FloatTensor of size 2x8]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = x.view(-1, 8); z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([4, 4]), torch.Size([16]), torch.Size([2, 8]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size(), y.size(), z.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read later:\n",
    "\n",
    "- 100+ Tensor operations, including transposing, indexing, slicing, mathematical operations, linear algebra, random numbers, etc., are described here http://pytorch.org/docs/torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Numpy Bridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting a Torch Tensor to a NumPy array and vice versa is a breeze.\n",
    "\n",
    "The Torch Tensor and NumPy array will share their underlying memory locations, and changing one will change the other."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Converting a Torch Tensor to a NumPy Array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       "[torch.FloatTensor of size 5]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.ones(5); a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.numpy(); b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5]), (5,))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.size(), b.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       "[torch.FloatTensor of size 5]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.add_(1); a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2.], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.2 Converting NumPy Array to Torch Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5); a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       "[torch.DoubleTensor of size 5]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.from_numpy(a); b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 2., 2.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.add(a, 1, out=a); a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       " 2\n",
       "[torch.DoubleTensor of size 5]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the Tensors on the CPU except a CharTensor support converting to NumPy and back."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 CUDA Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 1.9853 -1.9556 -0.3914  1.3319\n",
      " 0.6228 -0.7086 -2.2336 -0.4737\n",
      " 0.1612  2.8123 -0.9658  0.1332\n",
      "-4.1078  2.4472  0.2450  2.6391\n",
      "[torch.cuda.FloatTensor of size 4x4 (GPU 0)]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hasun\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\tensor.py:305: UserWarning: self and other not broadcastable, but have the same number of elements.  Falling back to deprecated pointwise behavior.\n",
      "  return self.add(other)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    x = x.cuda()\n",
    "    y = y.cuda()\n",
    "    print(x+y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.9926 -0.9778 -0.1957  0.6659\n",
       " 0.3114 -0.3543 -1.1168 -0.2368\n",
       " 0.0806  1.4061 -0.4829  0.0666\n",
       "-2.0539  1.2236  0.1225  1.3195\n",
       "[torch.cuda.FloatTensor of size 4x4 (GPU 0)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Autograd: automatic differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTorch 中所有神经网络的核心是 autograd 自动求导包. 我们先来简单介绍一下, 然后我们会去训练我们的第一个神经网络.\n",
    "\n",
    "autograd 自动求导包针对张量上的所有操作都提供了自动微分操作. 这是一个逐个运行的框架, 这意味着您的反向传播是由您的代码如何运行来定义的, 每个单一的迭代都可以不一样.\n",
    "\n",
    "让我们用一些更简单的术语与例子来了解这些套路."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "autograd.Variable 是包的核心类. 它包装了张量, 并且支持几乎所有的操作. 一旦你完成了你的计算, 你就可以调用 .backward() 方法, 然后所有的梯度计算会自动进行.\n",
    "\n",
    "你还可以通过 .data 属性来访问原始的张量, 而关于该 variable（变量）的梯度会被累计到 .grad 上去.\n",
    "\n",
    "还有一个针对自动求导实现来说非常重要的类 - Function.\n",
    "\n",
    "Variable 和 Function 是相互联系的, 并且它们构建了一个非循环的图, 编码了一个完整的计算历史信息. 每一个 variable（变量）都有一个 .grad_fn 属性, 它引用了一个已经创建了 Variable 的 Function （除了用户创建的 Variable `` 之外 - 它们的 ``grad_fn is None ）.\n",
    "\n",
    "如果你想计算导数, 你可以在 Variable 上调用 .backward() 方法. 如果 Variable 是标量的形式（例如, 它包含一个元素数据）, 你不必指定任何参数给 backward(), 但是, 如果它有更多的元素. 你需要去指定一个 grad_output 参数, 该参数是一个匹配 shape（形状）的张量.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 1  1\n",
       " 1  1\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = Variable(torch.ones(2,2), requires_grad = True); x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "??Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 1  1\n",
       " 1  1\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(x.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对 x 做一个操作:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x+2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 3  3\n",
       " 3  3\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "y 是由前面计算返回的结果创建的, 因此它有一个 grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<AddBackward0 object at 0x0000018E86709400>\n"
     ]
    }
   ],
   "source": [
    "print(y.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对 y 做更多的操作:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = y*y*3\n",
    "out = z.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 27  27\n",
       " 27  27\n",
       "[torch.FloatTensor of size 2x2]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MulBackward0 object at 0x0000018E86709390>\n"
     ]
    }
   ],
   "source": [
    "print(z.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 27\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MeanBackward1 object at 0x0000018E86709128>\n"
     ]
    }
   ],
   "source": [
    "print(out.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Gradients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在, 让我们来反向传播, 并打印出 d(out)/dx 的梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 4.5000  4.5000\n",
      " 4.5000  4.5000\n",
      "[torch.FloatTensor of size 2x2]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "out.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你可以使用自动求导来做很多有趣的事情"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 1744.8168\n",
      "  381.7086\n",
      " -324.1007\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3)\n",
    "x = Variable(x, requires_grad=True)\n",
    "\n",
    "y = x*2\n",
    "while y.data.norm() < 1000:\n",
    "    y = y*2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      "  409.6000\n",
      " 4096.0000\n",
      "    0.4096\n",
      "[torch.FloatTensor of size 3]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
    "y.backward(gradients)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络可以使用 torch.nn 包构建.\n",
    "\n",
    "autograd 实现了反向传播功能, 但是直接用来写深度学习的代码在很多情况下还是稍显复杂, torch.nn 是专门为神经网络设计的模块化接口. nn 构建于 Autograd 之上, 可用来定义和运行神经网络. nn.Module 是 nn 中最重要的类, 可把它看成是一个网络的封装, 包含网络各层定义以及 forward 方法, 调用 forward(input) 方法, 可返回前向传播的结果.\n",
    "\n",
    "例如, 看看这个分类数字图像的网络:\n",
    "\n",
    "这是一个基础的前向传播(feed-forward)网络: 接收输入, 经过层层传递运算, 得到输出.\n",
    "\n",
    "一个典型的神经网络训练过程如下:\n",
    "- 定义具有一些可学习参数(或权重)的神经网络\n",
    "- 迭代输入数据集\n",
    "- 通过网络处理输入\n",
    "- 计算损失(输出的预测值与实际值之间的距离)\n",
    "- 将梯度传播回网络\n",
    "- 更新网络的权重, 通常使用一个简单的更新规则: weight = weight - learning_rate * gradient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Define the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1,6,5)\n",
    "        self.conv2 = nn.Conv2d(6,16,5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16*5*5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "    \n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "你只要在 nn.Module 的子类中定义了 forward 函数, backward 函数就会自动被实现(利用 autograd ). 在 forward 函数中可使用任何 Tensor 支持的操作.\n",
    "\n",
    "网络的可学习参数通过 net.parameters() 返回, net.named_parameters 可同时返回学习的参数以及名称."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " (0 ,0 ,.,.) = \n",
       "  -0.1377 -0.0486 -0.1041 -0.0642  0.1979\n",
       "  -0.0578 -0.0464 -0.1259  0.0284 -0.1032\n",
       "   0.0912 -0.1463 -0.0083 -0.0711  0.0294\n",
       "  -0.1213 -0.0842  0.0283  0.0021 -0.0767\n",
       "   0.0254 -0.0209  0.0785 -0.0872 -0.1044\n",
       " \n",
       " (1 ,0 ,.,.) = \n",
       "  -0.1658  0.1604 -0.1402 -0.1579 -0.0591\n",
       "  -0.0101 -0.1573 -0.1060 -0.0047 -0.1504\n",
       "  -0.1054  0.0037 -0.0780 -0.1407 -0.0740\n",
       "  -0.1652  0.1554  0.0547  0.1767  0.0983\n",
       "   0.1960  0.0347 -0.0231  0.1119  0.1727\n",
       " \n",
       " (2 ,0 ,.,.) = \n",
       "   0.1762  0.1409 -0.0056  0.0457 -0.1571\n",
       "  -0.0713 -0.0923  0.1977  0.1017 -0.0969\n",
       "  -0.1820  0.0845  0.1214  0.0332  0.1918\n",
       "  -0.1956  0.0005 -0.0193  0.0738  0.1144\n",
       "  -0.1110 -0.1502 -0.1704  0.1815 -0.1146\n",
       " \n",
       " (3 ,0 ,.,.) = \n",
       "  -0.1025  0.0161 -0.0549 -0.0122 -0.0675\n",
       "  -0.1648 -0.0270 -0.1541 -0.0468  0.0895\n",
       "  -0.1113  0.0895 -0.0699  0.1559 -0.0330\n",
       "   0.1724  0.1067 -0.0170 -0.1182 -0.1460\n",
       "   0.1507 -0.0528 -0.0422 -0.0883  0.1003\n",
       " \n",
       " (4 ,0 ,.,.) = \n",
       "  -0.1956  0.0618  0.0392  0.1288  0.0837\n",
       "   0.0143  0.1422  0.0740  0.1110 -0.0815\n",
       "   0.1824 -0.0832  0.1917 -0.1832  0.0251\n",
       "  -0.1867  0.0201 -0.1463 -0.1395 -0.0131\n",
       "  -0.0778 -0.1187  0.0680  0.0769  0.0777\n",
       " \n",
       " (5 ,0 ,.,.) = \n",
       "  -0.1492 -0.0290  0.0540  0.0924  0.1838\n",
       "  -0.1165  0.1234 -0.1304  0.1002  0.1356\n",
       "  -0.0169  0.0806 -0.1941  0.0046  0.0244\n",
       "   0.1398 -0.1420 -0.1200  0.0498 -0.1285\n",
       "   0.0643 -0.0779 -0.0963 -0.0392 -0.0387\n",
       " [torch.FloatTensor of size 6x1x5x5], Parameter containing:\n",
       " -0.0702\n",
       " -0.1436\n",
       " -0.0891\n",
       " -0.0880\n",
       " -0.1053\n",
       " -0.0167\n",
       " [torch.FloatTensor of size 6], Parameter containing:\n",
       " (0 ,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   0.4256  5.0177 -4.1250 -7.3577  5.8054\n",
       "  -1.8932 -2.5563 -5.2579 -0.8679 -5.5060\n",
       "  -0.4782  0.8879 -7.1321 -1.0897 -8.1426\n",
       "  -0.6866  2.6932 -5.9348  8.1155 -3.1019\n",
       "   5.9445  2.5259 -5.9120 -0.2946 -3.4753\n",
       " \n",
       " (0 ,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   2.0664  6.8838  6.6548 -6.5783 -1.4982\n",
       "  -1.3189 -4.8558 -1.0340  7.3326  5.1861\n",
       "   5.2397  1.5860  1.9858 -6.5142  7.9906\n",
       "  -3.7804  6.4986 -0.9774 -5.6399  1.1190\n",
       "   7.0111 -5.9207  3.6431 -7.2369 -6.9212\n",
       " \n",
       " (0 ,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -4.2806  4.4229 -4.1279  2.4194  7.2586\n",
       "   8.0681  2.2190 -7.8778  5.3123  5.5727\n",
       "  -3.2609  6.1108  7.7943 -6.9267  1.5653\n",
       "  -7.2618  7.2395 -2.7061  7.1351 -7.6754\n",
       "   4.4239 -4.4225 -1.6367 -7.4663  6.3713\n",
       " \n",
       " (0 ,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   2.8347 -7.3952 -0.5214 -2.9863  1.2110\n",
       "  -4.7799  6.5121 -1.1460  4.6524 -4.9887\n",
       "   1.0491 -3.6970  7.6681 -4.5449  3.8510\n",
       "  -0.4731 -7.6831  0.8977 -2.0126 -4.8471\n",
       "   3.6311 -5.3361 -1.2515 -7.2838 -3.0262\n",
       " \n",
       " (0 ,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   5.3655  2.0697 -1.4656 -3.5567 -7.2219\n",
       "   5.0395 -6.8994 -6.5067  3.3911 -7.3967\n",
       "  -0.7750  0.4910 -1.2370 -0.4851  3.9612\n",
       "  -0.4360 -5.0330  6.8819  2.2655 -2.0825\n",
       "  -7.4175  8.0273  2.3822 -3.2449 -7.7847\n",
       " \n",
       " (0 ,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -1.1362  1.2474 -2.7460  6.6348  0.1050\n",
       "  -6.6696 -7.4119  6.1321 -5.2956  4.6676\n",
       "   7.6846  2.9644 -4.8245  6.6143 -5.7901\n",
       "  -6.2236 -0.9121 -2.3175  4.9319 -6.7937\n",
       "   8.0666 -4.7973  3.8206 -2.2165 -2.6977\n",
       "      ⋮ \n",
       " \n",
       " (1 ,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   7.7251 -4.0522  0.7908 -3.1686  7.3845\n",
       "  -2.7407 -4.6836  1.2003  1.8880  2.1480\n",
       "  -1.8017  7.7119  6.3450 -5.9397 -6.7908\n",
       "   4.0324 -6.8395 -4.2529  1.6382 -5.7624\n",
       "  -8.1031  2.1912 -4.1590  6.3480 -2.0734\n",
       " \n",
       " (1 ,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   4.8483  3.6338  0.9648 -0.5484 -1.6041\n",
       "  -2.4323  0.4244  5.7227 -7.1406 -2.0872\n",
       "  -7.1168  4.9767 -4.9917 -3.2941 -6.4338\n",
       "   1.3047 -5.4839  0.5228  6.2998  1.7445\n",
       "   1.6620  2.6227 -0.3430  6.4077 -6.0583\n",
       " \n",
       " (1 ,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -3.5928 -0.9317  6.5901 -2.2705  1.1275\n",
       "   0.8173  4.6294 -7.5234  7.2052  0.0379\n",
       "   5.2933 -7.4078 -2.0896  4.0126 -8.0540\n",
       "  -1.1314  7.9427  5.1900  3.5106  7.4414\n",
       "   0.3865  2.4009  0.5111 -3.5538 -4.2124\n",
       " \n",
       " (1 ,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   7.0045 -4.0010  1.8156  7.6520 -6.8145\n",
       "   7.4504 -3.0169 -1.0740 -3.4153 -6.9601\n",
       "  -1.4266 -6.1136  5.3198 -0.8817  6.2013\n",
       "   5.4535  1.7361 -5.1807  1.8057  3.2132\n",
       "  -4.5727 -4.8624 -2.7339 -5.0194  4.3166\n",
       " \n",
       " (1 ,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -5.0009  6.4822  1.0879 -6.0992 -3.8482\n",
       "  -6.2423  2.3340  1.3211 -1.8333  6.2608\n",
       "  -2.1391 -4.8221 -7.0342 -3.1144  4.1962\n",
       "  -8.0245  1.8304  5.1258 -7.7297  2.5048\n",
       "  -2.8348 -4.4914 -3.6276  2.5724 -3.1883\n",
       " \n",
       " (1 ,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -2.4506  7.2660 -2.5580  2.6856 -3.3573\n",
       "  -1.1613  2.7176 -0.9912  7.6750  3.9700\n",
       "   2.0324  2.3592 -3.8102 -4.8954  5.4204\n",
       "  -8.1288  6.7764 -4.7351  4.7903 -3.5785\n",
       "   3.8005 -3.2754 -3.5767 -2.5036  4.3030\n",
       "      ⋮ \n",
       " \n",
       " (2 ,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   6.8031 -1.9623 -6.5475  2.0749  1.2530\n",
       "   1.5754 -7.9890  6.3961  3.9522 -4.2065\n",
       "  -6.9889 -6.7611 -4.9621 -3.9048  2.0982\n",
       "  -1.2153 -3.4899 -0.2722  1.6161  8.0500\n",
       "  -3.2956  1.2853 -5.2677  2.0559 -2.3659\n",
       " \n",
       " (2 ,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -1.2806  4.9781 -5.6274  3.0470 -2.4072\n",
       "  -2.2177 -0.3973 -6.1797 -5.2547 -4.7704\n",
       "  -6.0855 -7.7871 -0.1266  2.0299  6.4845\n",
       "   1.3096 -0.6855  2.8868  6.3725 -7.2986\n",
       "   5.3654  1.7103  5.1460  5.0677 -5.2943\n",
       " \n",
       " (2 ,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -7.4969 -1.7243 -0.7075 -6.9856 -3.3055\n",
       "   7.7653  3.7178  5.9566 -6.7899 -4.4489\n",
       "   1.7075  6.2422  1.0960  0.8073  2.8273\n",
       "   0.0893 -2.4563  8.0372 -3.8872  2.0652\n",
       "  -7.5910 -2.8931  2.6878  2.1976  7.7117\n",
       " \n",
       " (2 ,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   0.1611  2.7301 -5.8391  7.2863  5.8896\n",
       "  -4.5322 -5.7802  0.3333  3.3168 -3.9318\n",
       "   3.9344  5.7641  6.7684 -6.8884  7.9508\n",
       "  -0.4650  4.6400  1.1641  7.5103  4.1609\n",
       "   5.4605  2.7512  1.6111 -6.6111  1.5617\n",
       " \n",
       " (2 ,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   8.0695 -0.3616  2.5160  1.4938  3.3377\n",
       "   7.8956  2.8102  0.6734  3.7834  4.3185\n",
       "  -7.4711  1.2428 -2.8634  5.0998 -5.8646\n",
       "  -0.3465 -1.4575 -6.7803  2.6031  0.9200\n",
       "   2.1908 -5.8517  6.4015  3.9918  5.9897\n",
       " \n",
       " (2 ,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -5.3162  3.4065 -1.5991 -0.8723  6.9032\n",
       "   0.3901 -6.8630  5.8300  7.4635 -0.9335\n",
       "  -5.0593  3.6423  5.4481 -0.6100 -7.3740\n",
       "   4.9974  7.2097 -1.0841 -6.0149  1.3904\n",
       "  -7.0894  3.6977 -6.2044 -6.9163 -6.8456\n",
       " ...   \n",
       "      ⋮ \n",
       " \n",
       " (13,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   7.6531  1.1576 -8.1198 -4.6553  7.1833\n",
       "  -1.8810  7.0428 -7.8126 -4.6529 -6.0391\n",
       "   1.1696 -5.0530 -1.3757  3.4380 -5.2030\n",
       "  -2.4800  3.3708 -2.5105  1.1467  7.0503\n",
       "  -3.2155 -6.9710  2.3107  4.0464 -0.1104\n",
       " \n",
       " (13,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -6.4829 -6.5279  6.2588  6.4393  4.2057\n",
       "  -5.4527 -7.8934 -1.1980 -6.1677  8.1139\n",
       "   4.0714 -5.1685 -2.3839 -2.0585  5.1997\n",
       "   0.2560 -4.1388 -2.4141  4.8607  6.3985\n",
       "  -5.5149 -0.2642  0.2166  0.0702 -2.5256\n",
       " \n",
       " (13,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -5.2890 -2.9642  4.0223  1.6614  6.6540\n",
       "   6.1767  7.3795  5.7270 -0.4989 -6.7852\n",
       "   7.4604  0.9675 -2.1702  3.8437 -3.7548\n",
       "   0.2971 -0.0868  5.8257  1.6833  3.6532\n",
       "  -6.8491  5.5804  7.3623  1.0762  1.9788\n",
       " \n",
       " (13,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -0.6544 -3.3774 -2.4485 -6.0059 -1.6602\n",
       "  -5.3049  5.2430 -6.0796 -7.8622  7.8539\n",
       "  -2.6589  3.6531 -6.5554  3.8776 -7.0471\n",
       "   6.9617  5.5702 -4.1374  2.2649  1.0549\n",
       "   4.7213  2.9098 -2.2733  6.3596  6.0509\n",
       " \n",
       " (13,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -3.8500 -3.5860  1.0127  6.9993  2.9443\n",
       "   4.5665 -1.4551  4.2772  6.8796  2.8699\n",
       "  -0.9173  7.7687  6.6707 -4.2886  4.8957\n",
       "  -0.8797  4.1487 -2.6900  3.1788 -0.0848\n",
       "  -2.5941  5.7012  0.9317  5.5853 -7.8438\n",
       " \n",
       " (13,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   2.7764  6.6553  4.2550  0.9173  4.3935\n",
       "  -3.1216  4.7175  4.9583 -4.1019  2.7547\n",
       "   7.8232  2.6661  3.1938  4.6800  7.4029\n",
       "   7.8230 -2.1699  4.7222 -2.0187 -7.8869\n",
       "  -1.5437  0.5901 -4.9355  0.9350 -0.8694\n",
       "      ⋮ \n",
       " \n",
       " (14,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -0.7695 -6.3628  7.7711  5.5033  1.9860\n",
       "   3.1832 -4.6707 -6.9717  1.2778  7.5113\n",
       "  -0.0947  7.6925 -6.4190 -1.2283 -6.1048\n",
       "   2.2640  5.7073 -5.2320  6.0940  2.1301\n",
       "  -5.4411 -4.1367 -4.8820 -3.4317  1.9122\n",
       " \n",
       " (14,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -6.7575  5.2019  4.7753  7.1904  3.0336\n",
       "   7.0133 -5.7642  3.2651 -0.7867  5.4639\n",
       "   4.9248  6.6882 -2.3273 -4.9373  6.7873\n",
       "   5.9934 -5.0650  0.3389  4.7034  0.9789\n",
       "   4.3373 -4.4383  0.5701 -1.0019 -2.8201\n",
       " \n",
       " (14,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -4.6479 -5.4363 -2.8543  2.7397  1.0040\n",
       "   0.2414 -2.8442  1.6488  2.4017 -7.9025\n",
       "  -5.7299 -0.5790  6.9553  4.1530 -0.9176\n",
       "   5.9480 -3.4398  6.6467  7.1571 -0.5623\n",
       "  -2.8912  2.4444 -0.4334 -7.3184  2.5503\n",
       " \n",
       " (14,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -4.9501  2.2506 -3.1501  2.6840 -5.3574\n",
       "  -2.5055  6.7192 -2.1709  7.3701 -1.3983\n",
       "  -8.1333 -2.5508 -6.1407  2.2414  7.3599\n",
       "   0.0765  3.8503 -6.5372  7.2477 -4.8592\n",
       "   7.6308 -5.6050  4.3918  5.7359 -0.9716\n",
       " \n",
       " (14,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -5.7101  3.8036 -5.8502 -1.5438  0.7670\n",
       "  -0.5511  0.8114  3.1147 -0.4899  6.5555\n",
       "   1.4366 -5.0903 -3.7501  6.2996 -6.0004\n",
       "   4.8726 -6.1550 -1.9417  6.8436 -2.0724\n",
       "   3.4102  3.7902  0.9776  8.1268 -0.8040\n",
       " \n",
       " (14,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   4.2322  0.5884  7.7009  4.8925 -3.3310\n",
       "   6.0083  3.4276  0.4548  6.6656 -7.1701\n",
       "   7.0796  0.8162  2.9781 -5.5440 -2.3053\n",
       "  -5.4994 -5.0440 -1.2009 -1.6813  0.0607\n",
       "   3.4852  1.3286  7.7506 -7.3203  1.6453\n",
       "      ⋮ \n",
       " \n",
       " (15,0 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -0.5792  4.6668  2.5815 -2.1221 -7.1957\n",
       "  -6.2606 -4.5273  1.3810 -1.3772 -4.6916\n",
       "  -2.1192  5.6600 -8.0527 -1.6936 -0.8349\n",
       "   1.3580  1.6571 -6.2300  3.7421 -4.4782\n",
       "   4.2706 -6.6671  7.8347  4.5595 -0.6619\n",
       " \n",
       " (15,1 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -6.7923  2.9093  0.0390  1.6987  0.8403\n",
       "  -4.1036 -4.4870  5.1983 -5.2376  7.0455\n",
       "   5.6282  3.6869 -6.6022  6.7698  6.5106\n",
       "  -7.8088 -6.8383 -4.1372  6.1495 -3.8668\n",
       "   1.3129 -6.8674 -2.7239  3.6551 -0.2440\n",
       " \n",
       " (15,2 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -4.2038 -5.4016  6.3754 -3.4651  5.1414\n",
       "  -6.7977 -5.8546 -7.8304 -3.8921 -4.3598\n",
       "  -7.5665  5.5761  1.3189 -4.0869 -7.1637\n",
       "  -0.7073  3.0514  3.6821  0.8558 -3.2883\n",
       "   7.5791 -2.2301 -3.7185  6.6953  1.5837\n",
       " \n",
       " (15,3 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -0.7382 -6.9442  8.0538 -4.6668 -0.6494\n",
       "  -1.0141 -5.7262  6.6968 -0.4530  2.0362\n",
       "  -6.1422 -2.0460  3.7950  1.6239  7.8026\n",
       "  -3.8333  3.3773  3.1968 -3.4726  6.1968\n",
       "   2.8315  8.1378  5.9611 -0.8817 -6.6060\n",
       " \n",
       " (15,4 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "   5.8780  2.0524 -0.2739  7.9718  4.4487\n",
       "   4.7179  8.0668 -5.8726  0.1107 -4.7330\n",
       "   1.6797  6.7806 -1.6408  0.2384 -3.6688\n",
       "   0.2746 -0.1179 -1.2389 -1.6398 -3.2755\n",
       "   1.8098  4.2292  5.8019 -2.4672 -7.3366\n",
       " \n",
       " (15,5 ,.,.) = \n",
       " 1.00000e-02 *\n",
       "  -5.3383 -5.4220 -4.9811  0.2264  3.1310\n",
       "   0.0058  3.7080  2.3823 -6.9230 -4.3099\n",
       "  -3.5621  4.9041 -5.0534  1.9701 -2.0254\n",
       "   1.0527 -2.6515  7.6605  5.5414  0.0067\n",
       "  -7.1355  7.3344 -7.8776  6.3952 -5.4370\n",
       " [torch.FloatTensor of size 16x6x5x5], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "  -3.3241\n",
       "  -4.1803\n",
       "  -5.2797\n",
       "   0.4996\n",
       "  -4.0487\n",
       "  -6.6396\n",
       "  -6.6034\n",
       "  -4.4481\n",
       "  -5.7887\n",
       "  -6.3582\n",
       "  -6.4720\n",
       "   3.3515\n",
       "   6.8531\n",
       "   3.4677\n",
       "  -3.6444\n",
       "  -2.4272\n",
       " [torch.FloatTensor of size 16], Parameter containing:\n",
       "  6.6388e-03  2.2411e-02 -4.2610e-02  ...   1.4930e-02  4.1019e-02  1.4050e-02\n",
       " -1.8248e-02 -4.8297e-02  4.9604e-02  ...  -4.9977e-02 -1.3239e-02  4.9893e-02\n",
       "  3.8845e-02  2.9567e-02  1.5616e-02  ...   3.2918e-02 -2.5517e-02  2.6477e-02\n",
       "                 ...                   ⋱                   ...                \n",
       " -2.1961e-02  2.2180e-02  1.3816e-03  ...   3.7190e-02  3.9836e-02  3.0724e-02\n",
       "  1.4534e-02  1.6985e-02 -2.8404e-02  ...   2.7048e-02  2.4556e-02 -3.0846e-02\n",
       "  4.4802e-02 -1.0446e-02  3.8239e-02  ...   3.2053e-02  4.1492e-02 -5.7261e-03\n",
       " [torch.FloatTensor of size 120x400], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "  -2.4793\n",
       "   3.3969\n",
       "  -0.9525\n",
       "  -3.1964\n",
       "   1.0275\n",
       "   3.6854\n",
       "   1.1164\n",
       "  -2.4207\n",
       "   1.9717\n",
       "   3.1645\n",
       "  -0.9697\n",
       "   3.5178\n",
       "  -4.5811\n",
       "   3.0878\n",
       "  -3.9802\n",
       "  -1.8906\n",
       "  -0.8004\n",
       "   4.5856\n",
       "   1.8195\n",
       "  -3.5874\n",
       "   2.5393\n",
       "  -4.0073\n",
       "   3.2749\n",
       "   2.6589\n",
       "  -3.1651\n",
       "   0.8986\n",
       "   4.0282\n",
       "   4.0453\n",
       "  -4.4413\n",
       "   1.2596\n",
       "  -4.0749\n",
       "  -2.8545\n",
       "  -2.1550\n",
       "   4.2914\n",
       "  -2.5133\n",
       "   0.6396\n",
       "  -4.3018\n",
       "   1.6393\n",
       "  -1.9628\n",
       "  -0.0539\n",
       "  -4.1456\n",
       "  -2.9526\n",
       "   2.7958\n",
       "   1.7966\n",
       "   2.9564\n",
       "  -2.3296\n",
       "   3.9694\n",
       "   1.0226\n",
       "   3.5485\n",
       "   0.7812\n",
       "  -4.3667\n",
       "  -2.7354\n",
       "  -1.1221\n",
       "  -0.6699\n",
       "   1.3678\n",
       "  -3.2112\n",
       "  -3.4223\n",
       "  -4.6709\n",
       "  -4.4387\n",
       "  -3.9140\n",
       "  -3.7534\n",
       "  -3.6832\n",
       "  -0.4885\n",
       "  -4.5553\n",
       "  -2.8191\n",
       "   0.5636\n",
       "   2.1733\n",
       "   0.7121\n",
       "  -4.8419\n",
       "  -0.6673\n",
       "  -3.1641\n",
       "  -4.8633\n",
       "   2.4684\n",
       "   2.3605\n",
       "  -3.9858\n",
       "   3.1673\n",
       "   3.3891\n",
       "   3.8482\n",
       "  -1.1916\n",
       "  -0.9273\n",
       "  -4.1555\n",
       "  -2.0296\n",
       "  -3.8376\n",
       "  -0.8341\n",
       "   1.1044\n",
       "  -1.5348\n",
       "   4.8763\n",
       "   1.9768\n",
       "  -1.8123\n",
       "  -1.4061\n",
       "  -0.6111\n",
       "  -0.6552\n",
       "   3.1810\n",
       "   2.1936\n",
       "  -4.2904\n",
       "   1.8534\n",
       "   4.8345\n",
       "   2.0006\n",
       "  -0.7040\n",
       "   4.9173\n",
       "   4.3469\n",
       "  -4.5041\n",
       "  -1.6377\n",
       "  -4.6536\n",
       "  -0.9798\n",
       "   2.0965\n",
       "  -4.4990\n",
       "  -2.6458\n",
       "   3.6467\n",
       "   1.1821\n",
       "  -2.0616\n",
       "  -3.5172\n",
       "  -3.9287\n",
       "  -0.6602\n",
       "  -1.3806\n",
       "   2.2397\n",
       "  -2.6974\n",
       "  -4.7542\n",
       "  -4.7193\n",
       "  -4.1435\n",
       " [torch.FloatTensor of size 120], Parameter containing:\n",
       "  8.0002e-03 -1.9347e-02  8.2325e-02  ...  -8.1947e-02 -2.0165e-02 -6.9185e-02\n",
       "  4.6647e-02 -4.6384e-02 -6.7562e-02  ...  -8.0088e-02  3.8786e-02  2.6787e-02\n",
       " -2.2549e-02  4.1457e-02 -4.5010e-02  ...   8.9883e-02 -4.2341e-02  2.2673e-02\n",
       "                 ...                   ⋱                   ...                \n",
       " -8.7347e-03  1.1356e-02 -2.2243e-02  ...  -7.5240e-02 -3.2584e-02  5.1161e-02\n",
       " -2.0416e-03  1.6986e-02  2.0359e-02  ...   6.4841e-03 -2.0308e-02 -6.1549e-02\n",
       " -1.0777e-02 -7.3997e-02 -2.4715e-02  ...  -6.8548e-02  6.9944e-02 -3.5042e-02\n",
       " [torch.FloatTensor of size 84x120], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "  -8.4047\n",
       "  -0.9595\n",
       "   5.2956\n",
       "  -1.7716\n",
       "   7.5012\n",
       "  -3.7274\n",
       "  -2.7104\n",
       "  -8.6866\n",
       "  -8.3670\n",
       "   6.7201\n",
       "   1.5145\n",
       "  -8.4977\n",
       "  -7.4631\n",
       "   0.0595\n",
       "   7.2730\n",
       "   6.9418\n",
       "  -0.6724\n",
       "  -4.2416\n",
       "  -0.7461\n",
       "   0.1503\n",
       "  -2.7448\n",
       "   2.8486\n",
       "   7.8670\n",
       "   0.6933\n",
       "  -0.4912\n",
       "   2.6645\n",
       "   1.4844\n",
       "  -2.9719\n",
       "  -6.5098\n",
       "   0.4374\n",
       "  -4.2449\n",
       "  -6.2563\n",
       "  -6.5940\n",
       "  -6.1188\n",
       "   2.4102\n",
       "  -4.3918\n",
       "  -0.2154\n",
       "   8.8486\n",
       "   8.2479\n",
       "   6.2126\n",
       "   5.7797\n",
       "  -6.3739\n",
       "  -1.2944\n",
       "  -8.2778\n",
       "  -7.0947\n",
       "  -4.6994\n",
       "   2.6415\n",
       "   0.4243\n",
       "   8.9715\n",
       "  -2.9379\n",
       "  -7.2885\n",
       "   8.6445\n",
       "  -1.7352\n",
       "  -2.4382\n",
       "   4.0452\n",
       "  -6.8738\n",
       "  -1.5316\n",
       "   6.1214\n",
       "   7.2963\n",
       "  -2.7436\n",
       "   4.7079\n",
       "   6.8882\n",
       "   0.6147\n",
       "  -3.9822\n",
       "  -4.2095\n",
       "   2.2051\n",
       "   7.2386\n",
       "   0.2128\n",
       "   0.8888\n",
       "  -7.1187\n",
       "  -1.0355\n",
       "  -4.4139\n",
       "  -3.2843\n",
       "  -3.0441\n",
       "  -8.6945\n",
       "  -8.6025\n",
       "   7.0454\n",
       "   2.5345\n",
       "  -4.8669\n",
       "  -2.9902\n",
       "  -0.0177\n",
       "  -2.1918\n",
       "  -3.4294\n",
       "   8.3944\n",
       " [torch.FloatTensor of size 84], Parameter containing:\n",
       " \n",
       " Columns 0 to 9 \n",
       " -0.0185  0.0086  0.0639 -0.0675 -0.0099 -0.0135  0.0830  0.0909 -0.0686  0.0943\n",
       "  0.0077 -0.0920  0.0365  0.0810 -0.0801  0.0451 -0.1003  0.0431  0.1081 -0.0504\n",
       "  0.0818  0.0520  0.0907  0.0631  0.0575 -0.0623 -0.0241 -0.0682 -0.0607  0.0552\n",
       "  0.0526  0.0210 -0.0940 -0.0699  0.0828  0.0556 -0.0409  0.0797  0.0923 -0.0042\n",
       " -0.0899  0.0550  0.0049  0.0268 -0.0520  0.0485 -0.0630  0.0817 -0.0970 -0.0203\n",
       " -0.0830  0.0969 -0.0741  0.0706 -0.0459 -0.0277  0.0355  0.0903 -0.0258  0.0342\n",
       "  0.0475 -0.0735  0.1069 -0.0836 -0.0454  0.0371 -0.0742  0.0259 -0.0270 -0.0320\n",
       "  0.0036 -0.0909  0.0188  0.0356 -0.0673  0.0111 -0.0984  0.0305  0.0602  0.0287\n",
       "  0.0020  0.0450 -0.1056  0.1062  0.0617 -0.0271 -0.0046 -0.0031  0.0400 -0.0275\n",
       " -0.0266  0.0752  0.0058  0.0936  0.0077 -0.0547  0.0957 -0.0053  0.0867 -0.0378\n",
       " \n",
       " Columns 10 to 19 \n",
       "  0.1057 -0.0668  0.0325  0.0793 -0.0203 -0.1079  0.0857  0.0434 -0.0514 -0.0709\n",
       " -0.0053 -0.0859  0.1072 -0.0228 -0.0368 -0.1045 -0.0564  0.0719  0.0794  0.0492\n",
       "  0.0673 -0.0419 -0.0292 -0.0773 -0.0635 -0.0532  0.0939  0.0460  0.0312 -0.0745\n",
       "  0.1002  0.0010  0.0752  0.0597  0.0453 -0.0429 -0.0533  0.0821  0.0720 -0.0193\n",
       "  0.0299  0.0014  0.0352 -0.0708 -0.0568  0.0134  0.0800  0.0607 -0.0067  0.0755\n",
       " -0.0314  0.0551  0.0393 -0.0569  0.0376 -0.0863  0.0633 -0.0272 -0.0986  0.0887\n",
       "  0.1008 -0.0989  0.0893 -0.0038 -0.0525 -0.0074  0.0579  0.0934 -0.0463  0.0415\n",
       "  0.0523 -0.0040 -0.0193 -0.0516  0.1045 -0.0206 -0.0502  0.0102  0.0340  0.0178\n",
       " -0.0725  0.0035 -0.0455  0.0721  0.0351 -0.0568  0.0361 -0.0600 -0.0379  0.0171\n",
       "  0.0099 -0.0142 -0.0505  0.0720  0.1054  0.0556  0.0616 -0.0317 -0.1035 -0.0292\n",
       " \n",
       " Columns 20 to 29 \n",
       " -0.0319 -0.0093 -0.0491 -0.0334 -0.0676 -0.0050 -0.0220  0.0587 -0.0342 -0.1006\n",
       " -0.0247  0.0889 -0.0666 -0.1062  0.0330 -0.0187 -0.0237 -0.0385  0.1080 -0.0999\n",
       "  0.1082 -0.0372  0.0293  0.0803 -0.0772 -0.0910  0.0853 -0.0711 -0.0392  0.0395\n",
       "  0.0992  0.0542  0.1026  0.0023  0.0714 -0.0304 -0.0415  0.0065 -0.0764 -0.0783\n",
       "  0.0270 -0.0224 -0.0461 -0.0518  0.0079 -0.0525  0.0241 -0.0150  0.0781  0.0475\n",
       "  0.0264  0.0513  0.0730 -0.0454  0.0427 -0.0990 -0.1084 -0.0983  0.1088 -0.0181\n",
       " -0.0315 -0.0393  0.0328  0.0719 -0.0308 -0.0395 -0.0897 -0.0057  0.0483  0.0692\n",
       " -0.0790 -0.0191  0.0733  0.0539 -0.0433  0.0484 -0.0132 -0.0119  0.0455 -0.0757\n",
       " -0.0926 -0.0058 -0.0026  0.0629 -0.0228  0.0725 -0.0044  0.0714 -0.0283 -0.0882\n",
       " -0.0817 -0.0210  0.1051 -0.0747 -0.0594  0.0843  0.0853  0.0015  0.0171 -0.1065\n",
       " \n",
       " Columns 30 to 39 \n",
       " -0.0291 -0.0671  0.0343  0.0247  0.1067 -0.0629  0.1026  0.0372 -0.0268  0.0178\n",
       " -0.0078 -0.0072 -0.0909 -0.0102  0.0276 -0.0341 -0.0363  0.0790  0.0341 -0.0947\n",
       "  0.0044 -0.0093  0.0204 -0.0775  0.0020 -0.0338  0.0845  0.0809 -0.0640 -0.0879\n",
       " -0.0174 -0.0000  0.0790  0.0460  0.0625 -0.0671 -0.0420 -0.0935 -0.0502 -0.0096\n",
       " -0.0616  0.0601 -0.0474  0.0430  0.0013  0.0029  0.0752  0.0364 -0.0423 -0.0947\n",
       "  0.0301  0.0295  0.0500  0.0614 -0.0404 -0.0687  0.0995  0.0007 -0.0379 -0.0095\n",
       " -0.0331  0.1021  0.0543  0.0796 -0.0300 -0.0472 -0.0476 -0.0555  0.0390 -0.0302\n",
       "  0.1079  0.0268  0.1049 -0.0901  0.0055 -0.0437  0.0935  0.0455  0.0084 -0.0824\n",
       "  0.1012 -0.0513 -0.0528  0.0266 -0.0824 -0.0740 -0.0147 -0.0133 -0.0146 -0.0160\n",
       "  0.0821  0.0815 -0.0716  0.0476  0.0201 -0.0812 -0.0817  0.0353 -0.0605 -0.0171\n",
       " \n",
       " Columns 40 to 49 \n",
       " -0.0457 -0.0086  0.0448  0.0636  0.0024  0.0758 -0.1007 -0.0581  0.0877  0.0895\n",
       "  0.0095 -0.0346 -0.0182 -0.0615 -0.0226 -0.0515  0.0749 -0.0475  0.0388  0.0100\n",
       " -0.0306 -0.0256  0.1038 -0.1090  0.0636 -0.1054  0.0417 -0.0863 -0.0857 -0.0694\n",
       "  0.0058 -0.0651 -0.0084 -0.0974  0.0085 -0.0351 -0.0427  0.0269 -0.0453  0.0786\n",
       "  0.0050 -0.0013 -0.0187  0.0872 -0.0039 -0.0264 -0.0244  0.0368  0.0388  0.0539\n",
       "  0.0662  0.1027  0.0122  0.0530  0.0849 -0.0166  0.1044 -0.0618 -0.0886  0.0599\n",
       "  0.0996 -0.0787 -0.1050  0.0027 -0.0441 -0.1054  0.0506  0.0664 -0.0255  0.0785\n",
       " -0.0733  0.0593 -0.0260  0.1040  0.0447 -0.0243 -0.0018 -0.0378  0.0870  0.0650\n",
       " -0.0229 -0.0733 -0.0154  0.0565 -0.0166 -0.0173  0.0426  0.0193 -0.1054  0.0705\n",
       "  0.0851 -0.1061  0.0675  0.0993 -0.0773  0.0400  0.0335 -0.0096 -0.0674  0.0607\n",
       " \n",
       " Columns 50 to 59 \n",
       "  0.0885  0.0850  0.0009  0.0397 -0.0424  0.0662  0.0617 -0.0792 -0.0412  0.0859\n",
       " -0.0943 -0.0441  0.0849 -0.0297  0.0847 -0.0674 -0.0565  0.0566  0.0821 -0.0945\n",
       "  0.0107 -0.0356 -0.0094 -0.1073 -0.0762  0.0813  0.0641 -0.0181 -0.0592  0.0697\n",
       "  0.0164  0.0911 -0.0106  0.0562 -0.0678 -0.0287 -0.0434 -0.1069  0.0076  0.0084\n",
       " -0.0494  0.0881  0.1019  0.0916  0.0220  0.0958  0.0173  0.0472 -0.0979  0.0850\n",
       " -0.0010  0.0476 -0.0318 -0.0143  0.0206  0.0872 -0.0673  0.0013 -0.0889 -0.1056\n",
       "  0.0231  0.1055 -0.0322  0.0986 -0.0615  0.0097  0.0714  0.0374  0.1040 -0.0083\n",
       " -0.1037  0.0777 -0.0788 -0.0467  0.1072  0.0907 -0.0168 -0.1042  0.0138  0.0636\n",
       " -0.0793 -0.0267 -0.1038  0.0111 -0.0603  0.0011  0.0983  0.0817 -0.0190 -0.0510\n",
       " -0.0787  0.0304 -0.0015  0.0874 -0.0030 -0.0225  0.0391  0.0746 -0.0134  0.1003\n",
       " \n",
       " Columns 60 to 69 \n",
       " -0.0762 -0.0571 -0.0258 -0.1038  0.0984 -0.1017 -0.1034  0.0182  0.0431  0.0695\n",
       "  0.0306  0.0960  0.0249  0.0982 -0.0710  0.0586  0.0529  0.0593  0.1082  0.0011\n",
       "  0.0655  0.0943  0.0311 -0.0797 -0.0548  0.0354 -0.0037 -0.0119 -0.0272 -0.0856\n",
       "  0.0444  0.0729  0.0936  0.0543  0.0706 -0.0809  0.0694  0.0830  0.0587  0.1077\n",
       "  0.0776 -0.0377 -0.0877  0.0291  0.0613  0.0674 -0.0367  0.0615  0.0528  0.0830\n",
       "  0.0938  0.0402  0.0737 -0.0923  0.0866  0.0559 -0.0140  0.0758  0.0213  0.0587\n",
       "  0.0474  0.0739 -0.0616 -0.0622  0.0976  0.0620 -0.0528 -0.0960  0.1045  0.0922\n",
       " -0.0906  0.0394  0.0743 -0.0282  0.0258 -0.0767  0.1050 -0.0373 -0.0906 -0.0355\n",
       " -0.0043 -0.0858  0.0157 -0.0958 -0.0953  0.0075  0.0637 -0.0972 -0.0644 -0.0324\n",
       "  0.0631 -0.0888  0.0292  0.0023 -0.0024  0.0870  0.1015  0.0348 -0.0836 -0.0412\n",
       " \n",
       " Columns 70 to 79 \n",
       "  0.0248 -0.0201 -0.0115 -0.0275 -0.0500  0.0856 -0.0669  0.0098 -0.0670  0.1029\n",
       " -0.0972  0.0482  0.0245  0.0383  0.0517  0.0214 -0.0624  0.0164 -0.0896  0.0694\n",
       " -0.0089  0.0498  0.0802  0.0141 -0.0734  0.0277 -0.0247 -0.0264  0.0264 -0.0539\n",
       " -0.0213 -0.0234  0.0636  0.0098  0.0532  0.0952  0.0317  0.0056 -0.1040 -0.0930\n",
       " -0.0246 -0.0844 -0.0197 -0.0892 -0.0383 -0.0696  0.0616 -0.0832  0.0110 -0.0246\n",
       "  0.1052 -0.0200  0.0957 -0.0356 -0.0281 -0.0595 -0.0960  0.0802  0.0702  0.0095\n",
       " -0.0601 -0.0097 -0.1053 -0.0195  0.0599  0.0831  0.0382  0.0398 -0.0663 -0.0806\n",
       "  0.0587 -0.0251 -0.0876  0.0126  0.0914  0.1047  0.0271  0.0224 -0.0733 -0.0133\n",
       " -0.0893 -0.0471  0.0161  0.0965  0.0280  0.0870 -0.0196  0.0294  0.0178 -0.0743\n",
       " -0.0631 -0.0219  0.0010  0.0681 -0.0993  0.0032 -0.0402 -0.0149 -0.0712 -0.0481\n",
       " \n",
       " Columns 80 to 83 \n",
       "  0.0172  0.0299 -0.0581  0.1089\n",
       " -0.0599 -0.0656 -0.0279  0.0081\n",
       " -0.0667  0.0196 -0.0283  0.0715\n",
       "  0.0205  0.0216  0.0703  0.0879\n",
       "  0.0819  0.0106  0.0970  0.0049\n",
       " -0.0345 -0.0102  0.0997 -0.1039\n",
       " -0.0284 -0.0564 -0.0320  0.0122\n",
       "  0.0515  0.0253 -0.0698  0.0485\n",
       " -0.0489  0.0042 -0.0158  0.0476\n",
       "  0.1048 -0.0786  0.0523  0.0594\n",
       " [torch.FloatTensor of size 10x84], Parameter containing:\n",
       " 1.00000e-02 *\n",
       "  -2.2743\n",
       "  -8.4564\n",
       "  -0.1884\n",
       "  -6.4422\n",
       "  -1.2406\n",
       "  -0.3329\n",
       "   3.0754\n",
       "   2.9307\n",
       "  -0.6469\n",
       "   0.4129\n",
       " [torch.FloatTensor of size 10]]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = list(net.parameters()); params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "print(len(params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "(0 ,0 ,.,.) = \n",
       " -0.1377 -0.0486 -0.1041 -0.0642  0.1979\n",
       " -0.0578 -0.0464 -0.1259  0.0284 -0.1032\n",
       "  0.0912 -0.1463 -0.0083 -0.0711  0.0294\n",
       " -0.1213 -0.0842  0.0283  0.0021 -0.0767\n",
       "  0.0254 -0.0209  0.0785 -0.0872 -0.1044\n",
       "\n",
       "(1 ,0 ,.,.) = \n",
       " -0.1658  0.1604 -0.1402 -0.1579 -0.0591\n",
       " -0.0101 -0.1573 -0.1060 -0.0047 -0.1504\n",
       " -0.1054  0.0037 -0.0780 -0.1407 -0.0740\n",
       " -0.1652  0.1554  0.0547  0.1767  0.0983\n",
       "  0.1960  0.0347 -0.0231  0.1119  0.1727\n",
       "\n",
       "(2 ,0 ,.,.) = \n",
       "  0.1762  0.1409 -0.0056  0.0457 -0.1571\n",
       " -0.0713 -0.0923  0.1977  0.1017 -0.0969\n",
       " -0.1820  0.0845  0.1214  0.0332  0.1918\n",
       " -0.1956  0.0005 -0.0193  0.0738  0.1144\n",
       " -0.1110 -0.1502 -0.1704  0.1815 -0.1146\n",
       "\n",
       "(3 ,0 ,.,.) = \n",
       " -0.1025  0.0161 -0.0549 -0.0122 -0.0675\n",
       " -0.1648 -0.0270 -0.1541 -0.0468  0.0895\n",
       " -0.1113  0.0895 -0.0699  0.1559 -0.0330\n",
       "  0.1724  0.1067 -0.0170 -0.1182 -0.1460\n",
       "  0.1507 -0.0528 -0.0422 -0.0883  0.1003\n",
       "\n",
       "(4 ,0 ,.,.) = \n",
       " -0.1956  0.0618  0.0392  0.1288  0.0837\n",
       "  0.0143  0.1422  0.0740  0.1110 -0.0815\n",
       "  0.1824 -0.0832  0.1917 -0.1832  0.0251\n",
       " -0.1867  0.0201 -0.1463 -0.1395 -0.0131\n",
       " -0.0778 -0.1187  0.0680  0.0769  0.0777\n",
       "\n",
       "(5 ,0 ,.,.) = \n",
       " -0.1492 -0.0290  0.0540  0.0924  0.1838\n",
       " -0.1165  0.1234 -0.1304  0.1002  0.1356\n",
       " -0.0169  0.0806 -0.1941  0.0046  0.0244\n",
       "  0.1398 -0.1420 -0.1200  0.0498 -0.1285\n",
       "  0.0643 -0.0779 -0.0963 -0.0392 -0.0387\n",
       "[torch.FloatTensor of size 6x1x5x5]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6, 1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(params[0].size()) # conv1's .weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 6, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "print(params[2].size()) # conv2's .weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "向前的输入是一个 autograd.Variable, 输出也是如此. 注意: 这个网络(LeNet)的预期输入大小是 32x32, 使用这个net on MNIST 数据集, 请将数据集中的图像调整为 32x32."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "(0 ,0 ,.,.) = \n",
       "  0.4358 -0.9095  0.7906  ...  -1.0737  1.2422 -0.1403\n",
       " -0.1645  1.8463  0.6987  ...   0.7927 -1.0154  1.9852\n",
       " -1.1381  0.0095  0.3846  ...  -0.8134 -0.0408 -0.5372\n",
       "           ...             ⋱             ...          \n",
       "  0.9422  1.5790 -0.6869  ...  -0.2393  0.3568  0.7193\n",
       " -0.4494  1.7387 -0.1912  ...   1.2886  0.0897 -0.1252\n",
       " -0.5512  0.1069  1.1763  ...   0.1900 -0.5371 -0.2634\n",
       "[torch.FloatTensor of size 1x1x32x32]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = Variable(torch.randn(1, 1, 32, 32)); input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "1.00000e-02 *\n",
       " -0.7488 -7.6292 -1.7524 -3.8006  1.8449  2.1247  4.5817  7.2483 -4.9109  2.6296\n",
       "[torch.FloatTensor of size 1x10]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = net(input); out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将网络中所有参数的梯度清零."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.zero_grad()\n",
    "out.backward(torch.randn(1,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note\n",
    "- torch.nn 只支持小批量(mini-batches), 不支持一次输入一个样本, 即一次必须是一个 batch.\n",
    "- 例如, nn.Conv2d 的输入必须是 4 维的, 形如 nSamples x nChannels x Height x Width.\n",
    "- 如果你只想输入一个样本, 需要使用 input.unsqueeze(0) 将 batch_size 设置为 1.\n",
    "- unsqueeze: Returns a new tensor with a dimension of size one inserted at the specified position."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在继续之前, 让我们回顾一下迄今为止所有见过的类.\n",
    "\n",
    "概括:\n",
    "- torch.Tensor - 一个 多维数组.\n",
    "- autograd.Variable - 包装张量并记录应用于其上的历史操作. 具有和 Tensor 相同的 API ,还有一些补充, 如 backward(). 另外 拥有张量的梯度.\n",
    "- nn.Module - 神经网络模块. 方便的方式封装参数, 帮助将其移动到GPU, 导出, 加载等.\n",
    "- nn.Parameter - 一种变量, 当被指定为 Model 的属性时, 它会自动注册为一个参数.\n",
    "- autograd.Function - 实现 autograd 操作的向前和向后定义 . 每个 Variable 操作, 至少创建一个 Function 节点, 连接到创建 Variable 的函数, 并 编码它的历史.\n",
    "\n",
    "在这一点上, 我们涵盖:\n",
    "- 定义一个神经网络\n",
    "- 处理输入并反向传播\n",
    "\n",
    "还剩下:\n",
    "- 计算损失函数\n",
    "- 更新网络的权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "损失函数采用 (output,target) 输入对, 并计算预测输出结果与实际目标的距离.\n",
    "\n",
    "在 nn 包下有几种不同的 损失函数 . 一个简单的损失函数是: nn.MSELoss 计算输出和目标之间的均方误差"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "  1\n",
       "  2\n",
       "  3\n",
       "  4\n",
       "  5\n",
       "  6\n",
       "  7\n",
       "  8\n",
       "  9\n",
       " 10\n",
       "[torch.FloatTensor of size 10]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = net(input)\n",
    "target = Variable(torch.arange(1, 11)); target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable containing:\n",
      " 38.3866\n",
      "[torch.FloatTensor of size 1]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.MSELoss()\n",
    "loss = criterion(output, target)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在, 如果你沿着 loss 反向传播的方向使用 .grad_fn 属性, 你将会看到一个如下所示的计算图:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input -> conv2d -> relu -> maxpool2d -> conv2d -> relu -> maxpool2d\n",
    "      -> view -> linear -> relu -> linear -> relu -> linear\n",
    "      -> MSELoss\n",
    "      -> loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以, 当我们调用 loss.backward(), 整个图与损失是有区别的, 图中的所有变量都将用 .grad 梯度累加它们的变量.\n",
    "\n",
    "为了说明, 让我们向后走几步:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<MseLossBackward object at 0x0000018E86771CC0>\n",
      "<AddmmBackward object at 0x0000018E86722A20>\n",
      "<ExpandBackward object at 0x0000018E86722B00>\n"
     ]
    }
   ],
   "source": [
    "print(loss.grad_fn) #MSELoss\n",
    "print(loss.grad_fn.next_functions[0][0]) # Linear\n",
    "print(loss.grad_fn.next_functions[0][0].next_functions[0][0]) #relu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了反向传播误差, 我们所要做的就是 loss.backward(). 你需要清除现有的梯度, 否则梯度会累加之前的梯度.\n",
    "\n",
    "现在我们使用 loss.backward(), 看看反向传播之前和之后 conv1 的梯度."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.bias.grad before backward\n",
      "Variable containing:\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      " 0\n",
      "[torch.FloatTensor of size 6]\n",
      "\n",
      "conv1.bias.grad after backward\n",
      "Variable containing:\n",
      " 0.0622\n",
      "-0.0056\n",
      "-0.0335\n",
      "-0.0065\n",
      "-0.0679\n",
      "-0.1064\n",
      "[torch.FloatTensor of size 6]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "net.zero_grad()\n",
    "\n",
    "print('conv1.bias.grad before backward')\n",
    "print(net.conv1.bias.grad)\n",
    "\n",
    "loss.backward()\n",
    "\n",
    "print('conv1.bias.grad after backward')\n",
    "print(net.conv1.bias.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在, 我们已经看到了如何使用损失函数."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "稍后阅读:\n",
    "- 神经网络包包含各种模块和损失函数, 形成深度神经网络的构建模块. 完整的文件列表 在这里: http://pytorch.org/docs/nn\n",
    "        \n",
    "接下来学习的唯一东西是:\n",
    "- 更新网络的权重"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Update the weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "实践中使用的最简单的更新规则是随机梯度下降( SGD ):\n",
    "\n",
    "weight = weight - learning_rate * gradient\n",
    "我们可以使用简单的 python 代码来实现这个:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "for f in net.parameters():\n",
    "    f.data.sub_(f.grad.data * learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然而, 当你使用神经网络时, 你需要使用各种不同的更新规则, 比如 SGD, Nesterov-SGD, Adam, RMSProp等. 为了实现这个功能, 我们建立了一个包: torch.optim 实现所有这些方法. 使用它非常的简单:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# create your optimizer\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "# in your training loop:\n",
    "optimizer.zero_grad() # zero the gradient buffers (same effect as net.zero_grad())\n",
    "output = net(input)\n",
    "loss = criterion(output, target)\n",
    "loss.backward()\n",
    "optimizer.step() # does the update"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note\n",
    "- 观察如何使用手动设置梯度清零 optimizer.zero_grad() . 需要手动清零的原因在 `Backprop`_ 中已经说明了(梯度会累加之前的梯度)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "就是这个, 你已经看到了如何定义神经网络, 计算损失并更新网络的权重.\n",
    "\n",
    "现在你可能会想,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 What about data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一般来说, 当你不得不处理图像, 文本, 音频或者视频数据时, 你可以使用标准的 Python 包将数据加载到一个 numpy 数组中. 然后你可以将这个数组转换成一个 torch.*Tensor.\n",
    "- 对于图像, 会用到的包有 Pillow, OpenCV .\n",
    "- 对于音频, 会用的包有 scipy 和 librosa.\n",
    "- 对于文本, 原始 Python 或基于 Cython 的加载, 或者 NLTK 和 Spacy 都是有用的.\n",
    "- 特别是对于 vision, 我们已经创建了一个叫做 torchvision, 其中有对普通数据集如 Imagenet, CIFAR10, MNIST 等和用于图像数据的转换器, 即 torchvision.datasets 和 torch.utils.data.DataLoader.\n",
    "\n",
    "这提供了巨大的便利, 避免了编写重复代码.\n",
    "\n",
    "在本教程中, 我们将使用 CIFAR10 数据集. 它有: ‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’,‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’ 这些类别. CIFAR10 中的图像大小为 3x32x32 , 即 32x32 像素的 3 通道彩色图像."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Training an image classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们将按顺序执行以下步骤:\n",
    "- 加载 CIFAR10 测试和训练数据集并规范化 torchvision\n",
    "- 定义一个卷积神经网络\n",
    "- 定义一个损失函数\n",
    "- 在训练数据上训练网络\n",
    "- 在测试数据上测试网络"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Loading and normalizing CIFAR10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 torchvision, 加载 CIFAR10 非常简单."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torchvision 数据集的输出是范围 [0, 1] 的 PILImage 图像. 我们将它们转换为归一化范围是[-1,1]的张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data_pytorch\\cifar-10-python.tar.gz\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data_pytorch', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data_pytorch', train=False, download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "让我们展示一些训练图像, 只是为了好玩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " deer frog deer bird\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def imshow(img):\n",
    "    img = img/2 + 0.5 # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)))\n",
    "    \n",
    "# get some random training images\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# print labels\n",
    "print(''.join('%5s' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Define a Convolution Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "从神经网络部分复制神经网络, 并修改它以获取 3 通道图像(而不是定义的 1 通道图像)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Define a Loss function and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们使用交叉熵损失函数( CrossEntropyLoss )和随机梯度下降( SGD )优化器."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss() # It is useful when training a classification problem with C classes\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Train the network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是事情开始变得有趣的时候. 我们只需循环遍历数据迭代器, 并将输入提供给网络和优化器."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.225\n",
      "[1,  4000] loss: 1.841\n",
      "[1,  6000] loss: 1.683\n",
      "[1,  8000] loss: 1.591\n",
      "[1, 10000] loss: 1.496\n",
      "[1, 12000] loss: 1.477\n",
      "[2,  2000] loss: 1.396\n",
      "[2,  4000] loss: 1.368\n",
      "[2,  6000] loss: 1.341\n",
      "[2,  8000] loss: 1.318\n",
      "[2, 10000] loss: 1.308\n",
      "[2, 12000] loss: 1.285\n",
      "Finished training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(2):\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        inputs, labels = data\n",
    "        # get the inputs\n",
    "        inputs, labels = Variable(inputs), Variable(labels)\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.data[0]\n",
    "        if i%2000 == 1999:  # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' % (epoch+1, i+1, running_loss/2000))\n",
    "            running_loss = 0.0\n",
    "            \n",
    "print('Finished training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Test the network on the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "我们在训练数据集上训练了2遍网络, 但是我们需要检查网络是否学到了什么.\n",
    "\n",
    "我们将通过预测神经网络输出的类标签来检查这个问题, 并根据实际情况进行检查. 如果预测是正确的, 我们将样本添加到正确预测的列表中.\n",
    "\n",
    "好的, 第一步. 让我们显示测试集中的图像以便熟悉."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GroundTruth:  truck  truck   deer    dog \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "print('GroundTruth: ', ' '.join('%5s ' % classes[labels[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好的, 现在让我们看看神经网络认为这些例子是什么:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(Variable(images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-1.5766  5.8518 -2.8199 -0.7995 -3.8474 -1.7429  1.0140 -3.4272 -1.3595  7.4869\n",
       " 0.5550 -0.4066 -1.0618  0.7625 -0.5766 -0.3012 -0.7758  0.2896 -0.8108  2.3638\n",
       "-0.5015 -1.1385  1.2889  0.3613  2.1235  0.0498  1.4985 -0.1753 -0.9031 -1.4824\n",
       "-2.5734 -2.4960  1.5330  1.9933  1.4879  2.8868  2.6786  1.9077 -3.7640 -3.0354\n",
       "[torch.FloatTensor of size 4x10]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "输出的是10个类别的能量. 一个类别的能量越高, 则可以理解为网络认为越多的图像是该类别的. 那么, 让我们得到最高能量的索引:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  truck  truck   deer    dog \n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs.data, 1)\n",
    "print('Predicted: ', ' '.join('%5s ' % classes[predicted[j]] for j in range(4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果看起来不错.\n",
    "\n",
    "让我们看看网络如何在整个数据集上执行."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 55 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum()\n",
    "    \n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "训练的准确率远比随机猜测(准确率10%)好, 证明网络确实学到了东西.\n",
    "\n",
    "嗯, 我们来看看哪些类别表现良好, 哪些类别表现不佳:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of plane : 64 %\n",
      "Accuracy of   car : 48 %\n",
      "Accuracy of  bird : 32 %\n",
      "Accuracy of   cat : 33 %\n",
      "Accuracy of  deer : 42 %\n",
      "Accuracy of   dog : 57 %\n",
      "Accuracy of  frog : 72 %\n",
      "Accuracy of horse : 69 %\n",
      "Accuracy of  ship : 63 %\n",
      "Accuracy of truck : 71 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "for data in testloader:\n",
    "    images, labels = data\n",
    "    outputs = net(Variable(images))\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    c = (predicted == labels).squeeze() # Returns a tensor with all the dimensions of input of size 1 removed.\n",
    "    \n",
    "    for i in range(4):\n",
    "        label = labels[i]\n",
    "        class_correct[label] += c[i]\n",
    "        class_total[label] += 1\n",
    "        \n",
    "for i in range(10):\n",
    "    print('Accuracy of %5s : %2d %%' % (classes[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "好的, 接下来呢?\n",
    "\n",
    "我们如何在 GPU 上运行这些神经网络?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Training on GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "就像你如何将一个张量传递给GPU一样, 你将神经网络转移到GPU上. 这将递归遍历所有模块, 并将其参数和缓冲区转换为CUDA张量:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=(2, 2), stride=(2, 2), dilation=(1, 1), ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "请记住, 您必须将输入和目标每一步都发送到GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果发现在 GPU 上并没有比 CPU 提速很多, 实际上是因为网络比较小, GPU 没有完全发挥自己的真正实力.\n",
    "\n",
    "练习: 尝试增加网络的宽度(第一个 nn.Conv2d 的参数2和第二个 nn.Conv2d 的参数1 它们需要是相同的数字), 看看你得到什么样的加速."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目标达成:\n",
    "- 深入了解PyTorch的张量库和神经网络.\n",
    "- 训练一个小的神经网络来分类图像."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Training on multiple GPUs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果你希望使用所有 GPU 来看更多的 MASSIVE 加速, 请查看可选 可选: 数据并行 http://pytorch.apachecn.org/cn/tutorials/beginner/blitz/data_parallel_tutorial.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  5 Where do I go next?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 训练神经网络玩电子游戏\n",
    "- 在 imagenet 上培训最先进的 ResNet 网络\n",
    "- 利用生成对抗网络训练人脸生成器\n",
    "- 使用 Recurrent LSTM 网络训练单词语言模型\n",
    "- 更多的例子\n",
    "- 更多教程\n",
    "- 在论坛上讨论 PyTorch\n",
    "- 与 Slack 上与其他用户聊天"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Data Parallelism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个教程中, 我们将会学习如何在多个GPU上使用 DataParallel .\n",
    "\n",
    "在 PyTorch 中使用 GPU 是一件很容易的事情.你可以像下面这样轻松的将一个模型分配到一个 GPU 上."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "随后, 你可以将你的所有张量拷贝到上面的GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytensor = my_tensor.gpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "此处请注意: 如果只是调用 mytensor.gpu() 是不会将张量拷贝到 GPU 的.你需要将它赋给一个 新的张量, 这个张量就能在 GPU 上使用了.\n",
    "\n",
    "在多个 GPU 上运行前向、反向传播是一件很自然的事情, 然而, PyTorch 默认情况下只会用到一个GPU, 可以通过使用 DataParallel 使你的模型并行运行, 在多个GPU上运行这些操作也将变得非常简单:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.DataParallel(model)b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是教程的核心内容, 我们将在随后进行详细讲解"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1 Imports and parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "导入PyTorch模块和参数定义"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Parameters and DataLoaders\n",
    "input_size = 5\n",
    "output_size = 2\n",
    "\n",
    "batch_size = 32\n",
    "data_size = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2 Dummy DataSet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "只需要实现 getitem 就可以轻松的生成一个（随机）伪数据集, 如下代码所示:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomDataSet(Dataset):\n",
    "    def __init__(self, size, length):\n",
    "        self.len = length\n",
    "        self.data = torch.randn(length, size)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        return self.data[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "rand_loader = DataLoader(dataset=RandomDataSet(input_size, data_size), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 Simple Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在下面的示例中, 我们的模型只需要一个输入并且完成一个线性操作, 最后得 到一个输出.当然, 你可以在任意模型 (CNN,RNN,Capsule Net等) 运用 DataParallel\n",
    "\n",
    "我们在模型中设置了打印指令来监控输入和输出的张量大小, Please pay attention to what is printed at batch rank 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.fc = nn.Linear(input_size, output_size)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = self.fc(input)\n",
    "        print(\" In Model: input size\", input.size(), \"output size\", output.size())\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 Create Model and DataParallel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这是本教程的核心部分. 首先, 我们需要生成一个模型的实例并且检测我们是否拥有多个 GPU.如果有多个GPU , 我们可以使用 nn.DataParallel 来包装我们的模型, 然后我们 就可以将我们的模型通过 model.gpu() 施加于这些GPU上."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 4 GPUs!\n"
     ]
    }
   ],
   "source": [
    "model = Model(input_size, output_size)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "    \n",
    "    # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "    model = nn.DataParallel(model)\n",
    "    \n",
    "if torch.cuda.is_available():\n",
    "    model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5 Run the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "现在我们可以看到输入和输出张量的大小了."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hasun\\AppData\\Local\\Continuum\\anaconda3\\envs\\fastai\\lib\\site-packages\\torch\\cuda\\nccl.py:27: UserWarning: PyTorch is not compiled with NCCL support\n",
      "  warnings.warn('PyTorch is not compiled with NCCL support')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " In Model: input size In Model: input size In Model: input size In Model: input size    torch.Size([8, 5])torch.Size([8, 5])torch.Size([8, 5])torch.Size([8, 5])    output sizeoutput sizeoutput sizeoutput size    torch.Size([8, 2])torch.Size([8, 2])torch.Size([8, 2])torch.Size([8, 2])\n",
      "\n",
      "\n",
      "\n",
      "Outside: input size torch.Size([32, 5]) output_size torch.Size([32, 2])\n",
      " In Model: input size In Model: input size  In Model: input size In Model: input size torch.Size([8, 5])  torch.Size([8, 5])torch.Size([8, 5]) torch.Size([8, 5])  output size output sizeoutput size output size torch.Size([8, 2])  \n",
      "torch.Size([8, 2])torch.Size([8, 2])torch.Size([8, 2])\n",
      "\n",
      "\n",
      "Outside: input size torch.Size([32, 5]) output_size torch.Size([32, 2])\n",
      " In Model: input size In Model: input size  In Model: input size In Model: input size  torch.Size([8, 5]) torch.Size([8, 5])torch.Size([8, 5]) torch.Size([8, 5]) output size  output size output sizeoutput size torch.Size([8, 2])  torch.Size([8, 2])\n",
      "torch.Size([8, 2])torch.Size([8, 2])\n",
      "\n",
      "\n",
      "Outside: input size torch.Size([32, 5]) output_size torch.Size([32, 2])\n",
      " In Model: input size  In Model: input size In Model: input size In Model: input sizetorch.Size([1, 5])  torch.Size([1, 5])  torch.Size([1, 5])torch.Size([1, 5]) output size output size output size   output sizetorch.Size([1, 2])torch.Size([1, 2])torch.Size([1, 2])\n",
      " \n",
      "\n",
      "torch.Size([1, 2])\n",
      "Outside: input size torch.Size([4, 5]) output_size torch.Size([4, 2])\n"
     ]
    }
   ],
   "source": [
    "for data in rand_loader:\n",
    "    if torch.cuda.is_available():\n",
    "        input_var = Variable(data.cuda())\n",
    "    else:\n",
    "        input_var = Variable(data)\n",
    "    output = model(input_var)\n",
    "    print(\"Outside: input size\", input_var.size(),\n",
    "          \"output_size\", output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6 Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DataParallel 自动地将数据分割并且将任务送入多个GPU上的多个模型中进行处理. 在每个模型完成任务后, DataParallel 采集和合并所有结果, 并将最后的结果呈现给你."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
